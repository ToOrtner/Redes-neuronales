{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as mpl, cm\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primer problema: Cancer de Mamas\n",
    "\n",
    "M = 1 #Salida :  Maligno (T) , Benigno (F)\n",
    "N = 10 #Entradas\n",
    "P = 410 #instancias\n",
    "p_train = 350\n",
    "p_check = P - p_train\n",
    "\n",
    "#los usamos para entrenar\n",
    "entradas_train = np.random.normal(0, 0.5 , (p_train,N))\n",
    "tags_train = np.zeros((p_train,1))\n",
    "\n",
    "\n",
    "#se usan despues para verificar\n",
    "entradas_check  = np.random.normal(0, 0.5 , (p_check,N))\n",
    "tags_check = np.zeros((p_check,1))\n",
    "\n",
    "dataPath = 'tp1_ej1_training.csv'\n",
    "dataViewer = pd.read_csv(dataPath, names =['Z','a','b','c','d','e','f','g','h','i','j'])\n",
    "\n",
    "\n",
    "with open(dataPath) as csvfile:\n",
    "    dataCSV = csv.reader(csvfile, delimiter=',')\n",
    "    i=0\n",
    "    k=0\n",
    "    for row in dataCSV:\n",
    "        \n",
    "        if i < p_train:\n",
    "            \n",
    "            if row[0] == 'M':\n",
    "                tags_train[i][0] = 1\n",
    "            else:\n",
    "                tags_train[i][0] = -1\n",
    "\n",
    "            j=0\n",
    "            for col in range(1,len(row)):\n",
    "                entradas_train[i][j] = row[col]\n",
    "                j+=1\n",
    "            i +=1\n",
    "        else: \n",
    "            if row[0] == 'M':\n",
    "                tags_check[k][0] = 1\n",
    "            else:\n",
    "                tags_check[k][0] = -1\n",
    "\n",
    "            j=0\n",
    "            for col in range(1,len(row)):\n",
    "                entradas_check[k][j] = row[col]\n",
    "                j+=1\n",
    "            k+=1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_add(V):\n",
    "    bias = -np.ones( (len(V),1) )\n",
    "    return np.concatenate( (V,bias), axis=1)\n",
    "\n",
    "def bias_sub( V):\n",
    "    return V[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activacionEscalon (entrada, w):\n",
    "    return np.sign(np.dot(entrada, w))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def activacionSigmoidea(x,w):\n",
    "    return sigmoid(np.dot(x,w))\n",
    "\n",
    "def tangente(x,w):\n",
    "    return np.tanh(np.dot(x,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clase capa de la red\n",
    "# Es una base, podemos agregarle otros parametros por ahi\n",
    "class redNeuronal():\n",
    "    \n",
    "        \n",
    "    \n",
    "    def __init__(self, dim_capas, f_activ,lr,batch_size):\n",
    "        \n",
    "        self.dim_capas = dim_capas\n",
    "        self.entradas = dim_capas[0]\n",
    "        self.f_activ = f_activ\n",
    "        #dim_capas = [N,3,3,3,1]\n",
    "        self.W = np.array(1) #primera pos que sea nula\n",
    "        self.n = len(dim_capas)\n",
    "        self.lr = lr   #learning rate\n",
    "        self.B = batch_size\n",
    "        self.error = np.array(1)\n",
    "        \n",
    "        #creo las matrices de Weights\n",
    "        np.append(self.W, 0) #primera capa no tiene wieghts asociados\n",
    "        for k in range(1,self.n):\n",
    "            ww = np.random.uniform( 0, 1,(self.dim_capas[k-1]+1, self.dim_capas[k]))\n",
    "            np.append(self.W, ww)\n",
    "    \n",
    "        \n",
    "        \n",
    "    def fit(self,X,Z):\n",
    "      \n",
    "        H = np.random.permutation(X.shape[0]) #permuta con el numero de instancias\n",
    "        for k in range(len(H)):\n",
    "        \n",
    "            h = H[k]\n",
    "            Xh = X[h:h+self.B]\n",
    "            Zh = Z[h:h+self.B]\n",
    "            \n",
    "            #feed forward\n",
    "            Y = self.activation(Xh,self.B)\n",
    "            #print(Y[-1])\n",
    "            #correccion de pesos con backpropagation (en cada batch)\n",
    "            dW = self.backprop(Y,Zh)\n",
    "            dW = np.array(dW)\n",
    "            self.W = (self.W + dW) \n",
    "            \n",
    "            \n",
    "    def activation(self,Xh,B):\n",
    "        Y = np.array(1)\n",
    "        Y0 = np.zeros( (B , self.dim_capas[0]+1) )\n",
    "        Y0[:] = bias_add(Xh)\n",
    "        np.append(Y, Y0)\n",
    "        for i in range(1,self.n-1):\n",
    "            #creo todas las capas del medio con sus dims correspondientes\n",
    "            Yi = np.zeros((B, self.dim_capas[i]+1))\n",
    "            \n",
    "            Yi[:] = bias_add( self.f_activ( Y[i-1],self.W[i]) )   #funcion de act\n",
    "            np.append(Y, Yi)\n",
    "        Yn = np.zeros( (B, self.dim_capas[-1])) #capa de salida\n",
    "        Yn[:] = self.f_activ(Y[-1],self.W[-1]) #ultima capa con ultimos Weights\n",
    "        np.append(Y, Yn)\n",
    "        #print(Yn)\n",
    "        return Y\n",
    "    \n",
    "    \n",
    "    def backprop(self,Y, Z):\n",
    "        \n",
    "        dW = []\n",
    "        dW.append(0) #el primero no tiene weights\n",
    "        #creo los dW con las mismas dimensiones que sus respectivos W para no tener conflicto de cuentas\n",
    "        for i in range(1,self.n):\n",
    "            dWi = np.zeros_like(self.W[i])\n",
    "            \n",
    "            dW.append(dWi)\n",
    "        \n",
    "      \n",
    "        D = [0] * self.n   #lista vacia para los D's\n",
    "        \n",
    "        En = Z-Y[-1]  #error de ultima capa\n",
    "        dYn = 1-np.square(Y[-1])\n",
    "        Dn = En*dYn\n",
    "        D[-1] = Dn\n",
    "        for k in range(self.n-1,0,-1):\n",
    "            dW[k] = self.lr * np.dot(Y[k-1].T, D[k])\n",
    "            \n",
    "            Ei = np.dot(D[k], self.W[k].T)\n",
    "            dYi = 1-np.square(Y[k-1])\n",
    "            Di = bias_sub(Ei * dYi)\n",
    "            D[k-1] = Di\n",
    "        \n",
    "        np.append(self.error, np.mean( np.sum( np.square(En),axis=1)) )\n",
    "        \n",
    "        \n",
    "        return dW\n",
    "            \n",
    "    \n",
    "    def predict(self, Input):\n",
    "    \n",
    "        return self.activation(Input, Input.shape[0])[-1]\n",
    "\n",
    "        \n",
    "        \n",
    "    def accuracy(self, resultados, esperados):\n",
    "        n = resultados.shape[0]\n",
    "        aciertos = 0\n",
    "        for i in range(n):\n",
    "            if np.sign(resultados[i]) == np.sign(esperados[i]):\n",
    "                aciertos += 1\n",
    "                \n",
    "        return aciertos / n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-253-05659b46b4e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcapas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredNeuronal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcapas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtangente\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentradas_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtags_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(entradas_check[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentradas_check\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-252-a3179e72958e>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Z)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;31m#feed forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[1;31m#print(Y[-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;31m#correccion de pesos con backpropagation (en cada batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-252-a3179e72958e>\u001b[0m in \u001b[0;36mactivation\u001b[1;34m(self, Xh, B)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;31m#creo todas las capas del medio con sus dims correspondientes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mYi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_capas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mYi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_activ\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m   \u001b[1;31m#funcion de act\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mYn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_capas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#capa de salida\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "capas = [N, 7, 8, 15, 3, 1]\n",
    "red = redNeuronal(capas,tangente, 0.20, 1)\n",
    "red.fit(entradas_train,tags_train)\n",
    "#print(entradas_check[1])\n",
    "res = red.predict(entradas_check)\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]\n",
      " [0.97830168]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = redNeuronal(capas,tangente, 0.20, 1)\n",
    "\n",
    "res = red.predict(entradas_check)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.accuracy(res, tags_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers(X,S):\n",
    "    \n",
    "    #capas\n",
    "    Y0 = np.zeros( (1,S[0]+1) )\n",
    "    Y1 = np.zeros( (1,S[1]+1) )\n",
    "    Y2 = np.zeros( (1,S[2]+1) )\n",
    "    Y3 = np.zeros( (1,S[3]) )\n",
    "    \n",
    "    W1 = np.random.normal( 0, 0.5, (S[0]+1, S[1]))\n",
    "    W2 = np.random.normal( 0, 0.5, (S[1]+1, S[2]))\n",
    "    W3 = np.random.normal( 0, 0.5, (S[2]+1, S[3]))\n",
    "    \n",
    "    \n",
    "    #batch\n",
    "    B = 1\n",
    "    H = np.random.permutation(P)\n",
    "    \n",
    "    #learning rate y error por epoca\n",
    "    lr = 0.3\n",
    "    error = 0.0\n",
    "\n",
    "    for i in range(len(H)):\n",
    "        \n",
    "        h = H[i]\n",
    "\n",
    "        Xh = X[h:h+B]\n",
    "        Zh = Z[h:h+B]\n",
    "        \n",
    "        #feed forward \n",
    "        #activacion tanh (sigmoidea)\n",
    "        Y0[:] = bias_add(Xh)\n",
    "        Y1[:] = bias_add( np.tanh(np.dot(Y0,W1)))\n",
    "        Y2[:] = bias_add( np.tanh(np.dot(Y1,W2)))\n",
    "        Y3[:] = np.tanh(np.dot(Y2,W3))\n",
    "\n",
    "        dW1 = np.zeros_like(W1)\n",
    "        dW2 = np.zeros_like(W2)\n",
    "        dW3 = np.zeros_like(W3)\n",
    "        \n",
    "        #backpropagation\n",
    "        \n",
    "        E3 = Zh-Y3\n",
    "        dY3 = 1-np.square(Y3)\n",
    "        D3 = E3*dY3\n",
    "        \n",
    "        dW3 += lr * np.dot(Y2.T,D3)\n",
    "        \n",
    "        E2 = np.dot(D3, W3.T)\n",
    "        dY2 = 1-np.square(Y2)\n",
    "        D2 = bias_sub(E2*dY2)\n",
    "\n",
    "        dW2 += lr * np.dot( Y1.T, D2)\n",
    "\n",
    "        E1 = np.dot( D2, W2.T)\n",
    "        dY1 = 1-np.square(Y1)\n",
    "        D1 = bias_sub( E1*dY1)\n",
    "\n",
    "        dW1 += lr * np.dot( Y0.T, D1)\n",
    "\n",
    "        W1 += dW1\n",
    "        W2 += dW2\n",
    "        error += np.mean( np.sum( np.square(Zh-Y2),axis=1))\n",
    "    \n",
    "    #prueba con red entrenada\n",
    "    \n",
    "    \n",
    "    Y0 = np.zeros( (P,S[0]+1) )\n",
    "    Y1 = np.zeros( (P,S[1]+1) )\n",
    "    Y2 = np.zeros( (P,S[2]+1) )\n",
    "    Y3 = np.zeros( (P,S[3]) )\n",
    "    \n",
    "    Y0[:] = bias_add(X)\n",
    "    Y1[:] = bias_add( np.tanh(np.dot(Y0,W1)))\n",
    "    Y2[:] = bias_add(np.tanh(np.dot(Y1,W2)))\n",
    "    Y3[:] = np.tanh(np.dot(Y2,W3))\n",
    "    return Y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
